---
title: |
 | Estimation en temps réel de la tendance-cycle :
 | Apport de l’utilisation des filtres asymétriques dans la détection des points de retournement
subtitle: "Séminaire D2E"
author: "Alain Quartier-la-Tente"
departement: "20 septembre 2022"
division: |
    | Division Études macroéconomiques
logo: "img/logobeamer.png"
automaticcontents: true
output:
    beamer_presentation:
        template: template_Beamer.tex
        keep_tex: yes
        theme: TorinoTh
        slide_level: 3
        includes:
          in_header: preamble_beamer.tex
themeoptions: "coding=utf8,language=french"
classoption: 'usepdftitle=false,french' #handout
fontsize: 10pt
bibliography: [biblio.bib]
biblio-style: unsrtnat
natbiboptions: [numbers]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = F,
                      fig.align = 'center',
                      fig.path = "img/rmd-")
library(knitr)
library(kableExtra)
library(rjdfilters)
fig.ext <- "pdf"
# load(file = "tables.RData")
# mae <- readRDS("tables_revisions.RDS")$MAE
```

# Introduction

### La tendance-cycle (1)

$X_t$ (ex : IPI France) se décompose en plusieurs composantes inobservées :
$$
X_t=\onslide<2->{\underbrace{TC_t}_{\text{tendance-cycle}}}
\onslide<3->{
+\underbrace{S_t}_{\text{saisonnalité}}
}
\onslide<4->{
+\underbrace{I_t}_{\text{irrégulier}}
}
\text{ (décomposition additive)}
$$
\onslide<5>{tendance et cycle ici estimés \highlight{simultanément}}

\begin{tikzpicture}
\begin{axis}[enlarge x limits=false, ylabel={IPI France},ymin = 66,ymax=120, 
xtick={2010,2012,...,2020}, xticklabels={2010,2012,...,2020},width=\textwidth, height=0.7\textheight]
\only<1->{
\addplot[mark=none, black] coordinates {(2010,90.3) (2010.083,93.1) (2010.167,109.5) (2010.25,100.4) (2010.333,95.5) (2010.417,111.8) (2010.5,100.8) (2010.583,74.5) (2010.667,109) (2010.75,105) (2010.833,102.7) (2010.917,101.9) (2011,99) (2011.083,101.6) (2011.167,115.3) (2011.25,101.6) (2011.333,110.1) (2011.417,108.5) (2011.5,101) (2011.583,78.3) (2011.667,110) (2011.75,106.4) (2011.833,106.3) (2011.917,100.2) (2012,99.3) (2012.083,99.9) (2012.167,110.3) (2012.25,99.8) (2012.333,96.1) (2012.417,108.5) (2012.5,103.8) (2012.583,78.8) (2012.667,102.9) (2012.75,107.6) (2012.833,101.9) (2012.917,91.5) (2013,96.3) (2013.083,95.7) (2013.167,103.9) (2013.25,103.4) (2013.333,96.2) (2013.417,105.5) (2013.5,105.2) (2013.583,73.4) (2013.667,103.3) (2013.75,109.3) (2013.833,99) (2013.917,94.6) (2014,96.8) (2014.083,97.1) (2014.167,104.9) (2014.25,102.9) (2014.333,92.4) (2014.417,104.8) (2014.5,103.3) (2014.583,71.5) (2014.667,107.2) (2014.75,107.7) (2014.833,95.5) (2014.917,98.4) (2015,94.6) (2015.083,96.1) (2015.167,108.4) (2015.25,102.4) (2015.333,91) (2015.417,111.8) (2015.5,101.1) (2015.583,76.1) (2015.667,109.1) (2015.75,107.7) (2015.833,101.8) (2015.917,99.9) (2016,95.1) (2016.083,99.6) (2016.167,108.3) (2016.25,103.3) (2016.333,98.6) (2016.417,110.3) (2016.5,95.8) (2016.583,79.7) (2016.667,107.9) (2016.75,103.4) (2016.833,104.7) (2016.917,99.7) (2017,98.9) (2017.083,97.1) (2017.167,114.5) (2017.25,98) (2017.333,102.7) (2017.417,111.4) (2017.5,99.5) (2017.583,81.4) (2017.667,108.2) (2017.75,113.2) (2017.833,111) (2017.917,99.5) (2018,101.8) (2018.083,98.6) (2018.167,112.9) (2018.25,103) (2018.333,98.7) (2018.417,112.8) (2018.5,106.6) (2018.583,82.6) (2018.667,104.7) (2018.75,116) (2018.833,109.6) (2018.917,97.6) (2019,103.8) (2019.083,102) (2019.167,111.6) (2019.25,107.2) (2019.333,105.2) (2019.417,106) (2019.5,109.8) (2019.583,78.8) (2019.667,109) (2019.75,116.5) (2019.833,104) (2019.917,97.8) (2020,101) (2020.083,100.1) (2020.167,91.8) (2020.25,66.7) (2020.333,73.7) (2020.417,98.2) (2020.5,97.4) (2020.583,71.7) (2020.667,104.7) (2020.75,106.7) (2020.833,101.6) (2020.917,96.6)};}
\only<2->{
\addplot+[mark=none,blue] coordinates {(2010,96.6) (2010.083,97.1) (2010.167,97.9) (2010.25,98.9) (2010.333,99.7) (2010.417,100.2) (2010.5,100.3) (2010.583,100.4) (2010.667,100.5) (2010.75,101) (2010.833,101.9) (2010.917,102.8) (2011,103.4) (2011.083,103.7) (2011.167,103.5) (2011.25,102.8) (2011.333,102.1) (2011.417,101.5) (2011.5,101.2) (2011.583,101.4) (2011.667,101.7) (2011.75,102.1) (2011.833,102.4) (2011.917,102.4) (2012,102.1) (2012.083,101.6) (2012.167,101) (2012.25,100.6) (2012.333,100.4) (2012.417,100.4) (2012.5,100.4) (2012.583,100.2) (2012.667,99.6) (2012.75,99) (2012.833,98.4) (2012.917,98) (2013,98) (2013.083,98.3) (2013.167,98.8) (2013.25,99.2) (2013.333,99.4) (2013.417,99.4) (2013.5,99.2) (2013.583,98.9) (2013.667,98.6) (2013.75,98.4) (2013.833,98.4) (2013.917,98.5) (2014,98.7) (2014.083,98.9) (2014.167,98.8) (2014.25,98.7) (2014.333,98.5) (2014.417,98.3) (2014.5,98.2) (2014.583,98.1) (2014.667,98.2) (2014.75,98.2) (2014.833,98.3) (2014.917,98.5) (2015,98.7) (2015.083,99.1) (2015.167,99.4) (2015.25,99.8) (2015.333,100.3) (2015.417,100.7) (2015.5,101) (2015.583,101.3) (2015.667,101.3) (2015.75,101.2) (2015.833,101) (2015.917,100.7) (2016,100.6) (2016.083,100.6) (2016.167,100.7) (2016.25,100.8) (2016.333,100.8) (2016.417,100.8) (2016.5,100.6) (2016.583,100.4) (2016.667,100.3) (2016.75,100.5) (2016.833,100.9) (2016.917,101.5) (2017,102) (2017.083,102.3) (2017.167,102.4) (2017.25,102.3) (2017.333,102) (2017.417,101.9) (2017.5,102.3) (2017.583,102.9) (2017.667,103.7) (2017.75,104.4) (2017.833,104.7) (2017.917,104.6) (2018,104) (2018.083,103.4) (2018.167,103.1) (2018.25,103.1) (2018.333,103.3) (2018.417,103.6) (2018.5,103.9) (2018.583,104) (2018.667,104.2) (2018.75,104.4) (2018.833,104.7) (2018.917,105.1) (2019,105.5) (2019.083,105.8) (2019.167,105.9) (2019.25,105.7) (2019.333,105.4) (2019.417,105) (2019.5,104.6) (2019.583,104.2) (2019.667,103.7) (2019.75,103.4) (2019.833,103.2) (2019.917,103.1) (2020,103) (2020.083,103) (2020.167,103.2) (2020.25,103.6) (2020.333,104) (2020.417,104.4) (2020.5,104.5) (2020.583,104.4) (2020.667,103.9) (2020.75,103.3) (2020.833,102.8) (2020.917,102.5)};
}
\only<3->{
\addplot+[mark=none,green!60!black] coordinates {(2010,91) (2010.083,93.7) (2010.167,109.5) (2010.25,99.9) (2010.333,92.4) (2010.417,111.9) (2010.5,101.7) (2010.583,73.8) (2010.667,108.9) (2010.75,106) (2010.833,106.1) (2010.917,102.4) (2011,97.5) (2011.083,100.5) (2011.167,114.7) (2011.25,102.4) (2011.333,97) (2011.417,111.9) (2011.5,101.1) (2011.583,78.6) (2011.667,109.8) (2011.75,106.4) (2011.833,106.7) (2011.917,99.1) (2012,98.6) (2012.083,101.8) (2012.167,109.9) (2012.25,99.8) (2012.333,97.3) (2012.417,108.9) (2012.5,102.7) (2012.583,77.6) (2012.667,103.1) (2012.75,108.7) (2012.833,101.3) (2012.917,92.2) (2013,96.8) (2013.083,95.4) (2013.167,103.4) (2013.25,103.9) (2013.333,96.2) (2013.417,104.9) (2013.5,104.6) (2013.583,74.2) (2013.667,104) (2013.75,107.5) (2013.833,99.4) (2013.917,95.2) (2014,97.4) (2014.083,95.9) (2014.167,105.4) (2014.25,101.6) (2014.333,92.9) (2014.417,105.9) (2014.5,102.9) (2014.583,71.8) (2014.667,106.1) (2014.75,107.5) (2014.833,96.6) (2014.917,98.2) (2015,94.7) (2015.083,95.8) (2015.167,108.3) (2015.25,101.8) (2015.333,93.4) (2015.417,110.9) (2015.5,105.4) (2015.583,74.9) (2015.667,109.4) (2015.75,108.1) (2015.833,101.7) (2015.917,99.9) (2016,94.6) (2016.083,99.7) (2016.167,109.5) (2016.25,103) (2016.333,96.6) (2016.417,110.7) (2016.5,100.2) (2016.583,79.4) (2016.667,107.1) (2016.75,105.6) (2016.833,105.3) (2016.917,98) (2017,98.1) (2017.083,98.3) (2017.167,113.5) (2017.25,98.8) (2017.333,101.3) (2017.417,111.8) (2017.5,101.6) (2017.583,81.5) (2017.667,108.7) (2017.75,112.3) (2017.833,108.5) (2017.917,98.8) (2018,102.9) (2018.083,99.2) (2018.167,109.3) (2018.25,103.6) (2018.333,102.5) (2018.417,112) (2018.5,105.8) (2018.583,82.8) (2018.667,106.2) (2018.75,115.6) (2018.833,108.5) (2018.917,98.3) (2019,103.7) (2019.083,101.7) (2019.167,112.6) (2019.25,106.2) (2019.333,104.8) (2019.417,110.8) (2019.5,109.8) (2019.583,80.5) (2019.667,107.7) (2019.75,114.3) (2019.833,105.4) (2019.917,98.1) (2020,101) (2020.083,99.6) (2020.167,112.1) (2020.25,103.6) (2020.333,98.8) (2020.417,115.3) (2020.5,109.4) (2020.583,78.6) (2020.667,111.2) (2020.75,111.8) (2020.833,104.1) (2020.917,99.4)};
}
\only<4->{
\addplot[mark=none,red] coordinates {(2010,90.3) (2010.083,93.1) (2010.167,109.5) (2010.25,100.4) (2010.333,95.5) (2010.417,111.8) (2010.5,100.8) (2010.583,74.5) (2010.667,109) (2010.75,105) (2010.833,102.7) (2010.917,101.9) (2011,99) (2011.083,101.6) (2011.167,115.3) (2011.25,101.6) (2011.333,110.1) (2011.417,108.5) (2011.5,101) (2011.583,78.3) (2011.667,110) (2011.75,106.4) (2011.833,106.3) (2011.917,100.2) (2012,99.3) (2012.083,99.9) (2012.167,110.3) (2012.25,99.8) (2012.333,96.1) (2012.417,108.5) (2012.5,103.8) (2012.583,78.8) (2012.667,102.9) (2012.75,107.6) (2012.833,101.9) (2012.917,91.5) (2013,96.3) (2013.083,95.7) (2013.167,103.9) (2013.25,103.4) (2013.333,96.2) (2013.417,105.5) (2013.5,105.2) (2013.583,73.4) (2013.667,103.3) (2013.75,109.3) (2013.833,99) (2013.917,94.6) (2014,96.8) (2014.083,97.1) (2014.167,104.9) (2014.25,102.9) (2014.333,92.4) (2014.417,104.8) (2014.5,103.3) (2014.583,71.5) (2014.667,107.2) (2014.75,107.7) (2014.833,95.5) (2014.917,98.4) (2015,94.6) (2015.083,96.1) (2015.167,108.4) (2015.25,102.4) (2015.333,91) (2015.417,111.8) (2015.5,101.1) (2015.583,76.1) (2015.667,109.1) (2015.75,107.7) (2015.833,101.8) (2015.917,99.9) (2016,95.1) (2016.083,99.6) (2016.167,108.3) (2016.25,103.3) (2016.333,98.6) (2016.417,110.3) (2016.5,95.8) (2016.583,79.7) (2016.667,107.9) (2016.75,103.4) (2016.833,104.7) (2016.917,99.7) (2017,98.9) (2017.083,97.1) (2017.167,114.5) (2017.25,98) (2017.333,102.7) (2017.417,111.4) (2017.5,99.5) (2017.583,81.4) (2017.667,108.2) (2017.75,113.2) (2017.833,111) (2017.917,99.5) (2018,101.8) (2018.083,98.6) (2018.167,112.9) (2018.25,103) (2018.333,98.7) (2018.417,112.8) (2018.5,106.6) (2018.583,82.6) (2018.667,104.7) (2018.75,116) (2018.833,109.6) (2018.917,97.6) (2019,103.8) (2019.083,102) (2019.167,111.6) (2019.25,107.2) (2019.333,105.2) (2019.417,106) (2019.5,109.8) (2019.583,78.8) (2019.667,109) (2019.75,116.5) (2019.833,104) (2019.917,97.8) (2020,101) (2020.083,100.1) (2020.167,91.8) (2020.25,66.7) (2020.333,73.7) (2020.417,98.2) (2020.5,97.4) (2020.583,71.7) (2020.667,104.7) (2020.75,106.7) (2020.833,101.6) (2020.917,96.6)};}
\end{axis}
\end{tikzpicture} 

### La tendance-cycle (2)

Pour l'analyse conjoncturelle, on étudie généralement des séries désaisonnalisées
$$
X_t - S_t =TC_t
+I_t
$$

. . .

\medskip

La présence de l'irrégulier peut rendre l'interprétation difficile, un lissage supplémentaire peut être utilisé :
$$
(X_t - S_t) - I_t =TC_t
$$

. . . 

Tendance-cycle publiée par peu d'instituts (~~Insee~~, ONS, Statistics Canada, ABS) mais volonté de faire des bonnes pratiques au niveau européen (Destatis).

. . . 

Critères importants de la tendance-cycle :

1. minimiser les révisions

2. minimiser le nombre de faux points de retournement

3. détecter correctement et \highlight{rapidement} les (bons) points de retournement



### Estimations de la TC et moyennes mobiles (1)


\bcattention objectif différent de celui des méthodes d'analyse des cycles économiques


$TC_t$ généralement estimée sur une série \highlight{sans} saisonnalité

. . .

Méthode de décomposition X-13ARIMA une des plus utilisées : études de méthodes non-paramétriques pour estimer $TC_t$


. . .


\highlight{Moyennes mobiles} (ou \highlight{filtres linéaires}) omniprésents dans l'extraction de la tendance-cycle et la désaisonnalisation (e.g. : X-13ARIMA) :
$$
M_\theta(X_t)=\sum_{k=-p}^{+f}\theta_kX_{t+k}
$$

### Estimations de la TC et moyennes mobiles (1)


Appliquer $M_\theta$ sur $X_t=\e^{-i\omega t}$ va avoir deux effets : 
$$
M_{\theta}X_t = \sum_{k=-p}^{+f} \theta_k \e^{-i \omega (t+k)}
= \left(\sum_{k=-p}^{+f} \theta_k \e^{-i \omega k}\right)\cdot X_t = G_\theta(\omega)\e^{-i\Phi_\theta(\omega)} X_t
$$


::: {.incremental}

1. Multiplier le niveau par $G_{\theta}\left(\omega\right)$ (*gain*)

2. Créer un *déphasage* $\Phi_\theta(\omega)/\omega$ : affecte détection des points de retournement

:::




\begin{figure}[!ht]
\pgfplotsset{width=\textwidth,height=4cm,every axis legend/.append style={font=\footnotesize,
  at={(0.5,-0.1)},
  anchor=north}
    }
\begin{tikzpicture}
\begin{axis}[
xtick={0,3.14159,...,15.70795},
xticklabels={0,$\pi$,$2\pi$,$3\pi$,$4\pi$,$5\pi$}
]
\addplot[domain=0:5*pi,smooth]    plot (\x,{sin(\x * (pi/2) r)});
\addplot[domain=0:5*pi,smooth, dashed]
  plot (\x,{1/2*sin(\x* pi/2 r )+1/2*sin((\x -1) * pi/2 r)});
\draw[<->](axis cs: 1.5,1)--(axis cs: 1.5,0.7071068)
  node[pos=0.5, right]{\scriptsize $G_{\theta_0}(\omega)$};
\only<2->{
\draw[<->] (axis cs: 3, -0.70710680-0.05)--(axis cs: 3.5,-0.7071068-0.05)
  node[pos=0.5, below right]{\scriptsize $\Phi_{\theta_0}(\omega)$};}
\end{axis}
\end{tikzpicture}
\end{figure}


### Estimations de la TC et moyennes mobiles (2)

\faArrowCircleRight{} Généralement, utilisation de filtres \highlight{symétriques} ($p=f$ et $\theta_{-i}=\theta_i$)

$$
M_\theta(X_t)=\sum_{k=-p}^{+p}\theta_kX_{t+k}, \quad\text{avec }\theta_{-i}=\theta_i
$$

. . .


\faArrowCircleRight{} Pour l'estimation en \highlightbf{temps réel}, utilisation de filtres \highlight{asymétriques} ($f<p$) $\implies$ révision et détection avec retard des points de retournement (\highlight{déphasage})

$$
\text{ex : }M_\theta(X_t)=\sum_{k=-p}^{0}\theta_kX_{t+k}
$$

. . .

Solution classique : prolonger la série par prévision et utiliser filtre symétrique
\faArrowCircleRight{} revient à utiliser des filtres asymétriques optimisés avec certains critères   
\faArrowCircleRight{} sous-optimal pour séries très variables

### Illustration avec climats des affaires dans l'industrie manufacturière

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/climats_ex.pdf")
```
\footnotesize 
https://www.insee.fr/fr/statistiques/6522175

### Objectifs

Objectifs de cette étude :

-  Étudier et comparer des approches récentes pour l'extraction de la tendance-cycle en temps réel : Régression polynomiale locale (Proietti et Luati 2008); RKHS (Dagum et Bianconcini 2016) ; Optimisation sous contrainte d’une somme pondérée de critères (Grun-Rehomme *et ali* 2018, Wildi et McElroy, 2019)

. . .

- Montrer qu'il est possible d'établir une théorie générale englobant toutes ces méthodes

. . .

- Présenter le package \faIcon{r-project} `rjdfilters` https://github.com/palatej/rjdfilters


# Méthodes étudiées

## Filtre symétrique

### Moyenne mobile symétrique d'Henderson

::::{.columns}
:::{.column width=55%}

\footnotesize
```{r h13, out.height="0.4\\paperheight", fig.align="center"}
library(rjdfilters)
f <- lp_filter(6, kernel = "Henderson")
plot_coef(f, q = 6, legend = FALSE,
          main="Henderson 13 termes")
```
:::
:::{.column width=45%}

MM Henderson (utilisé dans X-13ARIMA) largement répandue pour estimer $TC_t$

\medskip

MM Henderson préserve les tendances polynomiales de degré 3 et minimise le critère de "lissage" ($\sum(\nabla^3\theta_i)^2$)

\medskip

Sur séries mensuelles : MM de 13 termes généralement

:::
::::

## Polynômes Locaux

### Polynômes Locaux : `rjdfilters::lp_filter()`

Hypothèse : $y_t=\mu_t+\varepsilon_t$ avec $\varepsilon_t\overset{i.i.d}{\sim}\mathcal N(0,\sigma^2)$

$\mu_t$ localement approchée par un polynôme de degré $d$:
$$
\forall j\in\left\llbracket -h,h\right\rrbracket : y_{t+j}=m_{t+j}+\varepsilon_{t+j},\quad m_{t+j}=\sum_{i=0}^{d}\beta_{i}j^{i}
$$

. . .

Estimation en utilisant les WLS avec *noyaux*: $\hat{\beta}=(X'KX)^{1}X'Ky$ et
$$
\hat{m}_{t}=\hat\beta_0=w'y=\sum_{j=-h}^{h}w_{j}y_{t-j}
\text{ \faArrowCircleRight{} équivalent à une moyenne mobile symétrique}
$$
\faArrowCircleRight{} Filtre de Henderson avec $d=3$ et noyau spécifique.

### Filtres asymétriques : `rjdfilters::lp_filter()`

1. Même méthode mais moins de données (DAF) $\iff$ minimiser les révisions sous mêmes contraintes polynomiales

\faArrowCircleRight{} **sans biais** mais **beaucoup de variance**

\faArrowCircleRight{} utilisé dans STL



\pause

2. Minimisation des révisions sous contraintes polynomiales :

    1. *Linear-Constant* (LC): $y_t$ linéaire and $v$ reproduit les constantes (\highlight{Musgrave})

    2. *Quadratic-Linear* (QL): $y_t$ quadratique et $v$ reproduit droites

    3. *Cubic-Quadratic* (CQ): $y_t$ cubique et $v$ reproduit tendances quadratiques

    \faArrowCircleRight{} Filtres asymétriques $v$ dépendent de "IC-Ratio"

. . .

\bcsmbh modèles simples facilement interprétables

\bcsmmh Déphasage non contrôlé \faArrowCircleRight{} méthode étendue dans `rjdfilters::lp_filter()`

. . .

\faDesktop{} Visualisation https://aqlt.shinyapps.io/FiltersProperties/

### Coefficients

```{r out.height="90%", echo=FALSE}
knitr::include_graphics("img/coefs_lp.pdf")
```


## Filtres et Reproducing Kernel Hilbert Space (RKHS)

### Filtres RKHS : `rjdfilters::rkhs_filter()`

- Utilisation de la théorie des RKHS pour approcher le filtre d'Henderson

- Avec $K_p$ une **fonction de noyau** définie sur $[-1,1]$, le filtre symétrique :
$$
\forall j\in\left\llbracket -h,h\right\rrbracket: w_{j}=\frac{K_p(j/b)}{\sum_{i=-h}^{^h}K_p(i/b)}
$$

\faArrowCircleRight{} avec $b=h+1$ et $K_p$ spécifique on retrouve le filtre d'Henderson


- Pour les filtres asymétriques :
$$
\forall j\in\left\llbracket -h,q\right\rrbracket: w_{a,j}=\frac{K_p(j/b)}{\sum_{i=-h}^{^q}K_p(i/b)}
$$

\faArrowCircleRight{} $b$ choisit par optimisation, e.g. minimisant les révisions ($b_{q,\Gamma}$), les révisions liées à la fonction de gain ($b_{q,G}$) et celles liées au déphasage ($b_{q,\varphi}$)

### Filtres asymétriques

::::{.columns}
:::{.column width=65%}

\bcsmmh Plusieurs extremum

\footnotesize
```{r rkhstimeliness, out.height="0.4\\paperheight", fig.align="center"}
library(rjdfilters)
fun <- rkhs_optimization_fun(horizon = 6,
            leads = 5, degree = 3,
            asymmetricCriterion = "Timeliness")
plot(fun, 5.6, 12, xlab = "b",
     ylab = "Timeliness", main = "6X5 filter")
rkhs_optimal_bw()
```
:::
:::{.column width=30%}

\bigskip

\bcsmbh Méthode généralisable à des filtres avec fréquences irrégulières

:::
::::

### Coefficients

```{r out.height="90%", echo=FALSE}
knitr::include_graphics("img/coefs_rkhs.pdf")
```



## Minimisation sous contrainte : FST et ATS

### Approche FST : `rjdfilters::fst_filter()`

Minimisation sous contrainte d'une somme pondérée de 3 critères :

$$
\begin{cases}
\underset{\theta}{\min} & J(\theta)=
\alpha F_g(\theta)+\beta S_g(\theta)+\gamma T_g(\theta)\\
s.c. & C\theta=a
\end{cases}
$$
$F_g$ fidélité (*fidelity*, réduction de variance $\sum_{k=-p}^{+f} \theta_k^2$), $S_g$ lissage  (*smoothness*, critère d'Henderson $\sum_{j}(\nabla^{3}\theta_{j})^{2}$), $T_g$ temporalité (*timeliness*, déphasage $\int_{0}^{2\pi/12}\rho_{\theta}(\omega)\sin(\varphi_{\theta}(\omega))^{2}\ud\omega$)

. . .

::: {.summary data-latex=""}
- \bcsmbh Solution unique
  
- \bcsmbh Filtres asymétriques indépendants des données et du filtre symétrique
  
- \bcsmmh Poids non normalisés
:::



### Approche ATS `rjdfilters::dfa_filter()` {.allowframebreaks}

Décomposition de l'EQM :
\begin{align*}
&\E{(y_{t}-\hat{y}_{t})^{2}}=\frac{1}{2\pi}\int_{-\pi}^{\pi}\left|\Gamma_s(\omega)-{\Gamma_\theta}(\omega)\right|^{2}h(\omega)\ud\omega \nonumber
\\&\quad=\frac{1}{2\pi}\times2\times\int_{0}^{\pi}\left|\Gamma_s(\omega)-{\Gamma_\theta}(\omega)\right|^{2}h(\omega)\ud\omega
\end{align*}
et
\begin{align*}
&\left|\Gamma_s(\omega)-\Gamma_\theta(\omega)\right|^{2}=\rho_s(\omega)^{2}+\rho_\theta(\omega)^{2} + \\
&\qquad \phantom{=}2\rho_s(\lambda)\rho_\theta(\lambda)\left(1-\cos(\varphi_s(\omega)-\varphi_\theta(\omega)\right) \\
 &\qquad =\left(\rho_s(\omega)-\rho_\theta(\omega)\right)^{2}+\\
&\qquad \phantom{=}4\rho_s(\lambda)\rho_\theta(\lambda)\sin^{2}\left(\frac{\varphi_s(\omega)-\varphi_\theta(\omega)}{2}\right)
\end{align*}

Ce qui conduit à 
\begin{align*}
A_w&= 2\int_0^{\omega_1}\left(\rho_s(\omega)-\rho_\theta(\omega)\right)^{2}h(\omega)\ud\omega\\
T_w&= 8\int_0^{\omega_1}\rho_s(\lambda)\rho_\theta(\lambda)\sin^{2}\left(\frac{\varphi_\theta(\omega)}{2}\right)h(\omega)\ud\omega\\
S_w&= 2\int_{\omega_1}^\pi\left(\rho_s(\omega)^{2}-\rho_\theta(\omega)\right)^{2}h(\omega)\ud\omega\\
R_w&= 8\int_{\omega_1}^\pi\rho_s(\lambda)\rho_\theta(\lambda)\sin^{2}\left(\frac{\varphi_\theta(\omega)}{2}\right)h(\omega)\ud\omega\\
\end{align*}

Minimisation d'une somme pondérée de 3 critères :
$$
\mathcal{M}(\vartheta_{1},\vartheta_{2})=\vartheta_{1}T_w(\theta)+\vartheta_{2}S_w(\theta)+(1-\vartheta_{1}-\vartheta_{2})A_w(\theta)
$$
$\implies$ minimisation sous contraintes linéaires avec $h(\omega)=1$


::: {.summary data-latex=""}
- \bcsmbh Poids ont un sens
  
- \bcsmmh Résidus pas toujours négligeables
  
- \bcsmmh Pas unicité de la solution
:::


### Difficulté du choix des poids

Comment choisir les poids dans FST et AST (DFA) ? 


::: {.incremental}

- Minimiser que la *timeliness* ? introduit trop de variance

- Minimiser les révisions ? on néglige le déphasage

- Garder les poids qui donnent des MM de meilleure qualité que les autres selon tous les critères ? Rien de satisfaisant

- Faire quadrillage du plan et une analyse empirique du déphasage ? Difficile à analyser -> utiliser des méthodes de réduction de dimension ?

:::


# Comparaison des méthodes

## Méthodologie
### Méthodologie

Comparaison des différentes méthodes sur séries simulées (avec 3 niveaux de variabilité) et séries réelles :

1. Estimation de la tendance-cycle à chaque date en utilisant les différentes méthodes et un filtre symétrique de 13 termes

. . .

2. À chaque date, estimation des points de retournement :

    - redressements : $y_{t-3}\geq y_{t-2}\geq y_{t-1}<y_t\leq y_{t+1}$

    - ralentissements : $y_{t-3}\leq y_{t-2}\leq y_{t-1}>y_t\geq y_{t+1}$

Déphasage = temps nécessaire pour détecter le bon point de retournement \highlight{sans révision}

. . .


3. Calcul des révisions avec deux critères :

$$
\mathbb E\left[
\left|\frac{
y_{t|t+q} - y_{t|last}
}{
y_{t|last}
}\right|
\right]\quad
\text{ et }
\quad
\mathbb E\left[
\left|\frac{
y_{t|t+q} - y_{t|t+q+1}
}{
y_{t|t+q+1}
}\right|
\right]
$$

### Séries simulées {.allowframebreaks}

De façon similaire à Darne et Dagum (2009), on simule $y_t= C_t+ T_t + I_t$ entre janvier 1960 et décembre 2020 :

- $C_t = \rho [\cos (2 \pi t / \lambda) +\sin (2 \pi t / \lambda)]$, $\lambda=72$ (cycles de 6 ans, 19 points de retournement détectables) 

- $T_t = T_{t-1} + \nu_t$ avec $\nu_t \sim \mathcal{N}(0, \sigma_\nu^2)$, $\sigma_\nu=0,08$

- $I_t = e_t$ avec $e_t \sim \mathcal{N}(0, \sigma_e^2)$

Niveau de variabilité :

- variabilité faible (rapport signal/bruit fort) : $\sigma_e^2=0,2$ et $\rho = 3,0,\, 3,5$ ou $4,0$ (0,9 $\geq$ I-C ratio $\geq$ 0,7)

- variabilité moyenne (rapport signal/bruit moyen) : $\sigma_e^2=0,3$ et $\rho = 1,5,\, 2,0$ ou $3,0$ (2,3 $\geq$ I-C ratio $\geq$ 1,4)

- variabilité forte (rapport signal/bruit élevé) : $\sigma_e^2=0,4$ et $\rho = 0,5,\, 0,7$ ou $1,0$ (8,9 $\geq$ I-C ratio $\geq$ 5,2)


```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/simul_data.pdf")
```

## Application sur séries simulées
### Résultats sur le déphasage (séries simulées)

```{r graphstpsimul, echo=FALSE, out.width="100%"}
img <- sprintf("img/simul_phase_shift_norev.%s", fig.ext)
knitr::include_graphics(img)
```


### Médiane des révisions (séries simulées)

Pour les séries à variabilité **moyenne** :


\begin{table}[!h]
\centering \footnotesize
\begin{tabular}{ccccccc}
\toprule
Méthode & $q=0$ & $q=1$ & $q=2$ & $q=3$ & $q=4$ & $q=5$\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\cellc{1}\textbf{MAE entre $q$\ieme{} et la dernière estimation}}\\
\cellc{1}\hspace{1em}LC & 0,21 & 0,10 & 0,03 & 0,03 & 0,03 & 0,01\\
\hspace{1em}QL (rel) & 1,6 & 1,0 & 1,3 & 1,5 & 1,3 & 1,1\\
\hspace{1em}CQ (rel) & 2,2 & 1,3 & 4,2 & 3,3 & 2,1 & 1,6\\
\hspace{1em}DAF (rel) & 2,3 & 1,5 & 4,9 & 3,5 & 2,2 & 1,5\\
\hspace{1em}$b_{q,\Gamma}$ (rel) & 3,1 & 2,3 & 1,1 & 3,6 & 3,5 & 3,9\\
\cellc{3}\hspace{1em}$b_{q,G}$ (rel) & \cellc{3} 4,1 & \cellc{3} 4,0 & 1,1 & 3,6 & 3,5 & 4,0\\
\cellc{2}\hspace{1em}$b_{q,\varphi}$ (rel) & 1,5 & 1,1 & 1,0 & 1,8 & 2,7 & \cellc{2} 8,7\\
\hspace{1em}\cellc{4}ARIMA (rel) & 1,0 & 1,0 & 1,1 & 1,1 & 1,1 & 1,0\\
\addlinespace[0.3em]
\multicolumn{7}{l}{\cellc{1}\textbf{MAE entre $q$\ieme{} et la $q+1$\ieme{} estimation}}\\
\cellc{1}\hspace{1em}LC & 0,19 & 0,10 & 0,02 & 0,01 & 0,07 & 0,01\\
\cellc{2}\hspace{1em}QL (rel) & 1,6 & \cellc{2}43,2 & 0,1 & 3,1 & 0,9 & 1,1\\
\hspace{1em}CQ (rel) & 2,3 & 0,2 & 4,3 & 7,3 & 1,4 & 1,6\\
\cellc{2}\hspace{1em}DAF (rel) & 3,5 & 2,6 & 4,6 & \cellc{2} 12,9 & 1,3 & 1,5\\
\cellc{2}\hspace{1em}$b_{q,\Gamma}$ (rel) & 2,1 & 2,9 & 3,7 & 0,3 & \cellc{2}16,2 & 3,9\\
\cellc{2-3}\hspace{1em}$b_{q,G}$ (rel) & \cellc{3}3,7 & \cellc{3}4,7 & \cellc{3}4,3 & 0,5 & \cellc{2}17,0 & 4,0\\
\cellc{2} \hspace{1em}$b_{q,\varphi}$ (rel) & 1,2 & 1,4 & 3,5 & 5,3 & 0,7 & \cellc{2}8,7\\
\hspace{1em}\cellc{4}ARIMA (rel) & 1,1 & 1,3 & 0,8 & \cellc{4}1,8 & \cellc{4} 2,3 & 1,0\\
\bottomrule
\end{tabular}
\end{table}

### Médiane des révisions (séries simulées)

Pour les séries à variabilité **faible** :

\begin{table}[!h]
\centering\footnotesize
\begin{tabular}{ccccccc}
\toprule
Méthode & $q=0$ & $q=1$ & $q=2$ & $q=3$ & $q=4$ & $q=5$\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{\textbf{MAE entre $q$ieme{} et la dernière estimation}}}\\
\hspace{1em}LC & 0,1 & 0,1 & 0,0 & 0,0 & 0,0 & 0,0\\
\hspace{1em}\cellc{1}QL (rel) & 1,7 & 1,1 & 1,2 & 1,1 & 1,0 & 0,9\\
\hspace{1em}CQ (rel) & 2,1 & 1,7 & \cellc{1} 4,9 & 3,1 & 1,8 & 1,1\\
\hspace{1em}DAF (rel) & 2,2 & 2,0 & 5,8 & 3,6 & 2,0 & 1,3\\
\hspace{1em}$b_{q,\Gamma}$ (rel) & 6,6 & 5,0 & 1,3 & 6,1 & \cellc{1}7,3 & \cellc{1}7,5\\
\hspace{1em}$b_{q,G} (rel)$ & \cellc{1}8,8 & \cellc{1}8,9 & 1,1 & 6,2 & 7,3 & 7,5\\
\hspace{1em}$b_{q,\varphi}$ (rel) & 2,6 & 1,9 & 1,3 & 1,7 & 3,3 & \cellc{1}9,8\\
\hspace{1em}ARIMA (rel) & 1,4 & 1,2 & 1,6 & 1,6 & 1,3 & 1,0\\
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{\textbf{MAE entre $q$ieme{} et la $q+1$ieme{} estimation}}}\\
\hspace{1em}LC & 0,1 & 0,0 & 0,0 & 0,1 & 0,0 & 0,0\\
\hspace{1em}QL (rel) & 1,4 & 1,3 & 0,0 & 1,8 & 1,5 & 0,9\\
\hspace{1em}CQ (rel) & 2,3 & 0,3 & 5,4 & 5,2 & 2,0 & 1,1\\
\hspace{1em}DAF (rel) & 1,6 & 0,7 & 5,8 & 7,8 & 2,2 & 1,3\\
\hspace{1em}$b_{q,\Gamma}$ (rel) & 3,4 & 22,8 & 8,7 & 0,5\cellc{1} & \cellc{1}12,8 & \cellc{1}7,5\\
\hspace{1em}$b_{q,G} (rel)$ & \cellc{1}13,7 & \cellc{1}10,2 & \cellc{1}11,6 & 0,8 & \cellc{1}9,1 & 7,5\\
\hspace{1em}$b_{q,\varphi}$ (rel) & 1,5 & 3,0 & 2,3 & 2,8 & 1,7 & \cellc{1}9,8\\
\hspace{1em}ARIMA (rel) & 2,5 & 1,2 & 0,3 & 2,1 & 1,7 & 1,0\\
\bottomrule
\end{tabular}
\end{table}

### Médiane des révisions (séries simulées)

Pour les séries à variabilité **forte** :

\begin{table}[!h]
\centering\footnotesize
\begin{tabular}{ccccccc}
\toprule
Méthode & $q=0$ & $q=1$ & $q=2$ & $q=3$ & $q=4$ & $q=5$\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{\textbf{MAE entre $q$ieme{} et la dernière estimation}}}\\
\hspace{1em}LC & 1,6 & 0,6 & 0,3 & 0,2 & 0,3 & 0,1\\
\hspace{1em}QL (rel) & 1,8 & 1,2 & 1,1 & 1,5 & 1,4 & 1,4\\
\hspace{1em}CQ (rel) & 2,1 & 2,2 & 5,0 & 4,1 & 2,7 & 2,1\\
\hspace{1em}DAF (rel) & 2,4 & 2,3 & 4,6 & 4,3 & 2,5 & 2,3\\
\hspace{1em}$b_{q,\Gamma}$ (rel) & 1,0 & 1,1 & 1,2 & 1,0 & 1,1 & 1,4\\
\hspace{1em}$b_{q,G} (rel)$ & 1,2 & 1,2 & 1,1 & 1,0 & 1,1 & 1,4\\
\hspace{1em}$b_{q,\varphi}$ (rel) & 1,2 & 1,2 & 1,2 & 1,9 & 3,4 & 10,7\\
\hspace{1em}ARIMA (rel) & 1,0 & 1,2 & 1,0 & 1,1 & 0,8 & 0,9\\
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{\textbf{MAE entre $q$ieme{} et la $q+1$ieme{} estimation}}}\\
\hspace{1em}LC & 0,7 & 0,4 & 0,1 & 0,0 & 0,2 & 0,1\\
\hspace{1em}QL (rel) & 2,0 & 1,5 & 0,1 & 3,5 & 2,5 & 1,4\\
\hspace{1em}CQ (rel) & 1,7 & 0,2 &\cellc{1} 19,1 & 9,2 & 1,4 & 2,1\\
\hspace{1em}DAF (rel) & \cellc{1}11,0 & 1,4 & 4,2 & \cellc{1}9,3 & 1,6 & 2,3\\
\hspace{1em}$b_{q,\Gamma}$ (rel) & 1,0 & 1,3 & 1,3 & 0,2 & 0,9 & 1,4\\
\hspace{1em}$b_{q,G} (rel)$ & 0,9 & 1,5 & 8,5 & 0,2 & 0,8 & 1,4\\
\hspace{1em}$b_{q,\varphi}$ (rel) & 1,2 & 1,6 & 3,3 & 4,3 & 1,0 & \cellc{1}10,7\\
\hspace{1em}ARIMA (rel) & \cellc{1}32,8 & 1,4 & 0,8 & 1,6 & 0,9 & 0,9\\
\bottomrule
\end{tabular}
\end{table}

## Un exemple : série des ventes au détail des États-Unis (en log)

### Estimations successives de la tendance-cycle (1)

```{r retailxlp, echo=FALSE, out.width="100%"}
series <- "RETAILx"
img <- sprintf("img/nber/%s_%s.%s",tolower(series),
               "lp",
               fig.ext)
knitr::include_graphics(img)
```

### Estimations successives de la tendance-cycle (2)

```{r retailxrkhs, echo=FALSE, out.width="100%"}
img <- sprintf("img/nber/%s_%s.%s",tolower(series),
               "rkhs_arima",
               fig.ext)
knitr::include_graphics(img)
```


### Prévisions implicites

Fonction `rjdfilters::implicit_forecast`

$$
\forall q, \underbrace{\sum_{i=-h}^0 v_iy_i + \sum_{i=1}^h v_iy_i*}_{\text{lissage par }v\text{ de la série prolongée}}
=\underbrace{\sum_{i=-h}^0 w_i^qy_i + \sum_{i=1}^h w_i^qy_i*}_{\text{lissage par }w^q\text{ de la série prolongée}}\text{ avec }\forall i > q,w_i^q=0
$$
Ce qui est équivalent à :
$$
\forall q, \quad \sum_{i=1}^h (v_i- w_i^q) y_i^*
=\sum_{i=-h}^0 (w_i^q-v_i)y_i.
$$
Matriciellement :

\begin{equation}
\resizebox{\textwidth}{!}{$
\begin{pmatrix}
  v_1 & v_2 & \cdots & v_h \\
  v_1 - w_1^1 & v_2 & \cdots & v_h \\
  \vdots & \vdots & \cdots & \vdots \\
   v_1 - w_1^{h-1} & v_2-w_2^{h-1} & \cdots & v_h
\end{pmatrix}
\begin{pmatrix}y_1^* \\ \vdots \\ y_h^*\end{pmatrix}=
\begin{pmatrix}
  w_{-h}^0 - v_{-h} & w_{-(h-1)}^0 - v_{-(h-1)} & \cdots & w_{0}^0 - v_{0} \\
  w_{-h}^1 - v_{-h} & w_{-(h-1)}^1 - v_{-(h-1)} & \cdots & w_{0}^1 - v_{0} \\
  \vdots & \vdots & \cdots & \vdots \\
  w_{-h}^{h-1} - v_{-h} & w_{-(h-1)}^{h-1} - v_{-(h-1)} & \cdots & w_{0}^{h-1} - v_{0}
\end{pmatrix}
\begin{pmatrix}y_{-h} \\ \vdots \\ y_0\end{pmatrix}.$}
\end{equation}


### Prévisions implicites (1)

```{r retailxiplp, echo=FALSE, out.width="100%"}
series <- "RETAILx"
img <- sprintf("img/nber/%s_%s_implicit_forecast.%s",tolower(series),
               "lp",
               fig.ext)
knitr::include_graphics(img)
```

### Prévisions implicites (2)

```{r retailxiprkhs, echo=FALSE, out.width="100%"}
img <- sprintf("img/nber/%s_%s_implicit_forecast.%s",tolower(series),
               "rkhs_arima",
               fig.ext)
knitr::include_graphics(img)
```


### Retour sur les climats des affaires dans l'industrie

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/climats_prev_impl.pdf")
```

\footnotesize

Méthode utilisée : LC avec IC-Ratio fixé

# Extensions

## Choix de la fenêtre

### Combien de termes utiliser les MM asymétriques ?  {.allowframebreaks}

Actuellement on utilise toujours autant de points dans le passé (6) que la MM symétriques pour les estimations intermédiaires : hypothèse raisonnable ? Faudrait-il utiliser plus ou moins de points dans le passé ?

Critères classiques : validation croisée, CP-Mallow, AIC, Rice-T :

$$
CV(\hat\mu)=\frac{1}{n-2h}\sum_{t=h+1}^{n-h}\frac{(y_t-\hat \mu_t)^2}{(1-w_0)^2}
$$
$$
CP(\hat\mu)=\frac{1}{\sigma^2}\sum_{t=h+1}^{n-h}(y_t-\hat \mu_t)^2 - (n-2h)(1-2w_0)
$$
Mais en général leur minimisation ne donne pas de bon résultats (critères peu discriminants)

Pistes à explorer :

1. Méthodes plus complexes de sélection de la fenêtre (e.g. Fan et Gijbels 1992)

2. Méthode des plus proches voisins : utiliser toujours le même nombre de points (e.g. toujours 13 points)

## Paramétrisation locale des méthodes polynomiales


### Estimation de la pente {.allowframebreaks}

Régression non paramétrique : $y_i=\mu(x_i)+\varepsilon_i$ avec $\varepsilon_i$ un terme d'erreur.

Avec Taylor, pour tout point $x_0$, si $\mu$ est différentiable $d$ fois, alors :
$$
\forall x \::\:\mu(x) = \mu(x_0) + \mu'(x_0)(x-x_0)+\dots +
\frac{\mu^{(d)}(x_0)}{d!}(x-a)^d+R_d(x),
$$


Régression polynomiale

Hypothèse : $y_t=\mu_t+\varepsilon_t$ avec $\varepsilon_t\overset{i.i.d}{\sim}\mathcal N(0,\sigma^2)$

$\mu_t$ localement approchée par un polynôme de degré $d$:
$$
\forall j\in\left\llbracket -h,h\right\rrbracket : y_{t+j}=\sum_{i=0}^{d}\beta_{i}j^{i}+\varepsilon_{t+j}
$$

Estimation en utilisant les WLS avec *noyaux*: $\hat{\beta}=(X'KX)^{1}X'Ky$ et
$$
\hat{m}_{t}=\hat\beta_0=e_1'\hat{\beta} =w'y=\sum_{j=-h}^{h}w_{j}y_{t-j}\text{ avec }
e_1=\begin{pmatrix}1\\ 0\\\vdots\\0\end{pmatrix}
$$
Et de la même façon :
$$
\begin{cases}
\hat\beta_1 = \widehat{\mu'(t)}= e_2'\hat{\beta}\qquad(\ne \widehat{\mu(t)}') \\
\hat\beta_2 = \widehat{\mu''(t)}= e_3'\hat{\beta}
\end{cases}
$$

Dans la méthode LC, en fin de période on suppose :
$$
y_t=\beta_0+\beta_1t+\varepsilon_t\text{ avec }\varepsilon_t\sim\mathcal N (0,\sigma^2)
$$
Filtres asymétriques dépendent du ratio $|\beta_1/\sigma|$ qui est toujours supposé constant : peu de sens au niveau global, notamment dans les périodes de points de retournement ($\beta_1\simeq 0$)


```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/local_ic_tp.pdf")
```



Idée : paramétrisation locale
$$
\begin{cases}
\hat\sigma^2=\frac{1}{n-2h}\sum_{t=h+1}^{n-h}\frac{(y_t-\hat \mu_t)^2}{1-2w_0^2+\sum w_i^2}\\
\beta_1\text{ et }\beta_2 \text{ estimés par MM (DAF par simplification)}
\end{cases}
$$

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/local_ic_mm.pdf")
```

Rmq: il y a (encore) de fortes révisions entre la première et deuxième estimation, on pourrait utiliser méthode QL pour avoir les estimateurs de la pente

### Résultats (1)

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/simul_phase_shift_localic_norev.pdf")
```


### Résultats (2)

Sur la série étudiée, les résultats sont très proches :

```{r , echo=FALSE, out.width="100%"}
img <- sprintf("img/nber/%s_%s.%s",tolower(series),
               "localic",
               fig.ext)
knitr::include_graphics(img)
```

### Résultats (3)

```{r , echo=FALSE, out.width="100%"}
series <- "RETAILx"
img <- sprintf("img/nber/%s_%s_implicit_forecast.%s",tolower(series),
               "localic",
               fig.ext)

knitr::include_graphics(img)
```


# Conclusion

## Conclusion
### Conclusion

- Dans la construction des filtres asymétriques:

1. on peut se restreindre à ceux qui conservent les polynômes de degré au plus 1 (et exclure les filtres QL, CQ et DAF)

\bigskip

. . .


2. on peut utiliser le filtre LC pour les estimations proches de l'estimation finale



\bigskip

. . .

- Dans certains cas des méthodes alternatives à la prévision ARIMA peuvent être utilisées \faIcon{arrow-circle-right} `rjdfilters` peut aider à comparer les résultats (`rjdfilters::x11()` pour les intégrer dans X-11)


### What next\bcquestion

- Etudes sur d'autres méthodes comme Vasyechko et Grun-Rehomme (2014) ou Feng et Schäfer (2021) ou l'extension des méthodes polynomiales avec $T_g$

\bigskip

. . .



- Impact des points atypiques ? quid des méthodes robustes ?



### Merci pour votre attention {.noframenumbering}

Package \faIcon{r-project}{}:

\href{https://github.com/palatej/rjdfilters}{\faGithub{} palatej/rjdfilters}

Plus d'exemples sur le package, voir SAPW 2022 :
https://community.amstat.org/governmentstatisticssection/conferences/pastconference210/seasonal-adjustment-practitioners-workshop-2022
