---
title: |
 | Estimation en temps réel de la tendance-cycle :
 | Apport de l’utilisation des filtres asymétriques dans la détection des points de retournement
subtitle: "CSI"
author: "Alain Quartier-la-Tente"
departement: "08 novembre 2023"
division: ""
logo: "img/logobeamer.png"
automaticcontents: true
output:
    beamer_presentation:
        template: template_Beamer.tex
        keep_tex: yes
        theme: TorinoTh
        slide_level: 3
        includes:
          in_header: preamble_beamer.tex
themeoptions: "coding=utf8,language=french"
classoption: 'usepdftitle=false,french' #handout
fontsize: 10pt
bibliography: [biblio.bib]
biblio-style: unsrtnat
natbiboptions: [numbers]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = F,
                      fig.align = 'center',
                      fig.path = "img/rmd-")
library(knitr)
library(kableExtra)
library(rjd3filters)
fig.ext <- "pdf"
# load(file = "tables.RData")
# mae <- readRDS("tables_revisions.RDS")$MAE
```

# Introduction

### Présentation 

Travaille à l'Insee depuis 2015 : aux enquêtes de conjoncture (2015-2017), en tant que méthodologue sur les CVS-CJO (2017-2019) puis en tant que chargé d'études macroéconomiques (2021-)

Ensai (2012-2015) puis Ensae (2019-2021) et inscription en thèse à temps partiel en 2021

. . .

Passionné de \faIcon{r-project}, développe et maintien plusieurs packages autour de la désaisonnalisation

### Travaux effectués

Principalement autour de l'utilisation de moyennes mobiles asymétriques pour l'estimation en temps réel de la tendance-cycle et la détection des points de retounement.

- Un document de travail Insee en cours avec code ouvert et entièrement reproductible, pour l'instant disponible ici https://aqlt.github.io/DT-est-tr-tc/

- Une soumission en cours au Journal of Official Statistics (JOS).

- Un package `rjd3filters` pour créer et manipuler les moyennes mobiles

- Divers présentations sur le contenu statistique et informatique.

. . .

NB : études rédigées seul

### La tendance-cycle (1)

$X_t$ (ex : IPI France) se décompose en plusieurs composantes inobservées :
$$
X_t=\onslide<2->{\underbrace{TC_t}_{\text{tendance-cycle}}}
\onslide<3->{
+\underbrace{S_t}_{\text{saisonnalité}}
}
\onslide<4->{
+\underbrace{I_t}_{\text{irrégulier}}
}
\text{ (décomposition additive)}
$$
\onslide<5>{tendance et cycle ici estimés \highlight{simultanément}}

\begin{tikzpicture}
\begin{axis}[enlarge x limits=false, ylabel={IPI France},ymin = 66,ymax=120, 
xtick={2010,2012,...,2020}, xticklabels={2010,2012,...,2020},width=\textwidth, height=0.7\textheight]
\only<1->{
\addplot[mark=none, black] coordinates {(2010,90.3) (2010.083,93.1) (2010.167,109.5) (2010.25,100.4) (2010.333,95.5) (2010.417,111.8) (2010.5,100.8) (2010.583,74.5) (2010.667,109) (2010.75,105) (2010.833,102.7) (2010.917,101.9) (2011,99) (2011.083,101.6) (2011.167,115.3) (2011.25,101.6) (2011.333,110.1) (2011.417,108.5) (2011.5,101) (2011.583,78.3) (2011.667,110) (2011.75,106.4) (2011.833,106.3) (2011.917,100.2) (2012,99.3) (2012.083,99.9) (2012.167,110.3) (2012.25,99.8) (2012.333,96.1) (2012.417,108.5) (2012.5,103.8) (2012.583,78.8) (2012.667,102.9) (2012.75,107.6) (2012.833,101.9) (2012.917,91.5) (2013,96.3) (2013.083,95.7) (2013.167,103.9) (2013.25,103.4) (2013.333,96.2) (2013.417,105.5) (2013.5,105.2) (2013.583,73.4) (2013.667,103.3) (2013.75,109.3) (2013.833,99) (2013.917,94.6) (2014,96.8) (2014.083,97.1) (2014.167,104.9) (2014.25,102.9) (2014.333,92.4) (2014.417,104.8) (2014.5,103.3) (2014.583,71.5) (2014.667,107.2) (2014.75,107.7) (2014.833,95.5) (2014.917,98.4) (2015,94.6) (2015.083,96.1) (2015.167,108.4) (2015.25,102.4) (2015.333,91) (2015.417,111.8) (2015.5,101.1) (2015.583,76.1) (2015.667,109.1) (2015.75,107.7) (2015.833,101.8) (2015.917,99.9) (2016,95.1) (2016.083,99.6) (2016.167,108.3) (2016.25,103.3) (2016.333,98.6) (2016.417,110.3) (2016.5,95.8) (2016.583,79.7) (2016.667,107.9) (2016.75,103.4) (2016.833,104.7) (2016.917,99.7) (2017,98.9) (2017.083,97.1) (2017.167,114.5) (2017.25,98) (2017.333,102.7) (2017.417,111.4) (2017.5,99.5) (2017.583,81.4) (2017.667,108.2) (2017.75,113.2) (2017.833,111) (2017.917,99.5) (2018,101.8) (2018.083,98.6) (2018.167,112.9) (2018.25,103) (2018.333,98.7) (2018.417,112.8) (2018.5,106.6) (2018.583,82.6) (2018.667,104.7) (2018.75,116) (2018.833,109.6) (2018.917,97.6) (2019,103.8) (2019.083,102) (2019.167,111.6) (2019.25,107.2) (2019.333,105.2) (2019.417,106) (2019.5,109.8) (2019.583,78.8) (2019.667,109) (2019.75,116.5) (2019.833,104) (2019.917,97.8) (2020,101) (2020.083,100.1) (2020.167,91.8) (2020.25,66.7) (2020.333,73.7) (2020.417,98.2) (2020.5,97.4) (2020.583,71.7) (2020.667,104.7) (2020.75,106.7) (2020.833,101.6) (2020.917,96.6)};}
\only<2->{
\addplot+[mark=none,blue] coordinates {(2010,96.6) (2010.083,97.1) (2010.167,97.9) (2010.25,98.9) (2010.333,99.7) (2010.417,100.2) (2010.5,100.3) (2010.583,100.4) (2010.667,100.5) (2010.75,101) (2010.833,101.9) (2010.917,102.8) (2011,103.4) (2011.083,103.7) (2011.167,103.5) (2011.25,102.8) (2011.333,102.1) (2011.417,101.5) (2011.5,101.2) (2011.583,101.4) (2011.667,101.7) (2011.75,102.1) (2011.833,102.4) (2011.917,102.4) (2012,102.1) (2012.083,101.6) (2012.167,101) (2012.25,100.6) (2012.333,100.4) (2012.417,100.4) (2012.5,100.4) (2012.583,100.2) (2012.667,99.6) (2012.75,99) (2012.833,98.4) (2012.917,98) (2013,98) (2013.083,98.3) (2013.167,98.8) (2013.25,99.2) (2013.333,99.4) (2013.417,99.4) (2013.5,99.2) (2013.583,98.9) (2013.667,98.6) (2013.75,98.4) (2013.833,98.4) (2013.917,98.5) (2014,98.7) (2014.083,98.9) (2014.167,98.8) (2014.25,98.7) (2014.333,98.5) (2014.417,98.3) (2014.5,98.2) (2014.583,98.1) (2014.667,98.2) (2014.75,98.2) (2014.833,98.3) (2014.917,98.5) (2015,98.7) (2015.083,99.1) (2015.167,99.4) (2015.25,99.8) (2015.333,100.3) (2015.417,100.7) (2015.5,101) (2015.583,101.3) (2015.667,101.3) (2015.75,101.2) (2015.833,101) (2015.917,100.7) (2016,100.6) (2016.083,100.6) (2016.167,100.7) (2016.25,100.8) (2016.333,100.8) (2016.417,100.8) (2016.5,100.6) (2016.583,100.4) (2016.667,100.3) (2016.75,100.5) (2016.833,100.9) (2016.917,101.5) (2017,102) (2017.083,102.3) (2017.167,102.4) (2017.25,102.3) (2017.333,102) (2017.417,101.9) (2017.5,102.3) (2017.583,102.9) (2017.667,103.7) (2017.75,104.4) (2017.833,104.7) (2017.917,104.6) (2018,104) (2018.083,103.4) (2018.167,103.1) (2018.25,103.1) (2018.333,103.3) (2018.417,103.6) (2018.5,103.9) (2018.583,104) (2018.667,104.2) (2018.75,104.4) (2018.833,104.7) (2018.917,105.1) (2019,105.5) (2019.083,105.8) (2019.167,105.9) (2019.25,105.7) (2019.333,105.4) (2019.417,105) (2019.5,104.6) (2019.583,104.2) (2019.667,103.7) (2019.75,103.4) (2019.833,103.2) (2019.917,103.1) (2020,103) (2020.083,103) (2020.167,103.2) (2020.25,103.6) (2020.333,104) (2020.417,104.4) (2020.5,104.5) (2020.583,104.4) (2020.667,103.9) (2020.75,103.3) (2020.833,102.8) (2020.917,102.5)};
}
\only<3->{
\addplot+[mark=none,green!60!black] coordinates {(2010,91) (2010.083,93.7) (2010.167,109.5) (2010.25,99.9) (2010.333,92.4) (2010.417,111.9) (2010.5,101.7) (2010.583,73.8) (2010.667,108.9) (2010.75,106) (2010.833,106.1) (2010.917,102.4) (2011,97.5) (2011.083,100.5) (2011.167,114.7) (2011.25,102.4) (2011.333,97) (2011.417,111.9) (2011.5,101.1) (2011.583,78.6) (2011.667,109.8) (2011.75,106.4) (2011.833,106.7) (2011.917,99.1) (2012,98.6) (2012.083,101.8) (2012.167,109.9) (2012.25,99.8) (2012.333,97.3) (2012.417,108.9) (2012.5,102.7) (2012.583,77.6) (2012.667,103.1) (2012.75,108.7) (2012.833,101.3) (2012.917,92.2) (2013,96.8) (2013.083,95.4) (2013.167,103.4) (2013.25,103.9) (2013.333,96.2) (2013.417,104.9) (2013.5,104.6) (2013.583,74.2) (2013.667,104) (2013.75,107.5) (2013.833,99.4) (2013.917,95.2) (2014,97.4) (2014.083,95.9) (2014.167,105.4) (2014.25,101.6) (2014.333,92.9) (2014.417,105.9) (2014.5,102.9) (2014.583,71.8) (2014.667,106.1) (2014.75,107.5) (2014.833,96.6) (2014.917,98.2) (2015,94.7) (2015.083,95.8) (2015.167,108.3) (2015.25,101.8) (2015.333,93.4) (2015.417,110.9) (2015.5,105.4) (2015.583,74.9) (2015.667,109.4) (2015.75,108.1) (2015.833,101.7) (2015.917,99.9) (2016,94.6) (2016.083,99.7) (2016.167,109.5) (2016.25,103) (2016.333,96.6) (2016.417,110.7) (2016.5,100.2) (2016.583,79.4) (2016.667,107.1) (2016.75,105.6) (2016.833,105.3) (2016.917,98) (2017,98.1) (2017.083,98.3) (2017.167,113.5) (2017.25,98.8) (2017.333,101.3) (2017.417,111.8) (2017.5,101.6) (2017.583,81.5) (2017.667,108.7) (2017.75,112.3) (2017.833,108.5) (2017.917,98.8) (2018,102.9) (2018.083,99.2) (2018.167,109.3) (2018.25,103.6) (2018.333,102.5) (2018.417,112) (2018.5,105.8) (2018.583,82.8) (2018.667,106.2) (2018.75,115.6) (2018.833,108.5) (2018.917,98.3) (2019,103.7) (2019.083,101.7) (2019.167,112.6) (2019.25,106.2) (2019.333,104.8) (2019.417,110.8) (2019.5,109.8) (2019.583,80.5) (2019.667,107.7) (2019.75,114.3) (2019.833,105.4) (2019.917,98.1) (2020,101) (2020.083,99.6) (2020.167,112.1) (2020.25,103.6) (2020.333,98.8) (2020.417,115.3) (2020.5,109.4) (2020.583,78.6) (2020.667,111.2) (2020.75,111.8) (2020.833,104.1) (2020.917,99.4)};
}
\only<4->{
\addplot[mark=none,red] coordinates {(2010,90.3) (2010.083,93.1) (2010.167,109.5) (2010.25,100.4) (2010.333,95.5) (2010.417,111.8) (2010.5,100.8) (2010.583,74.5) (2010.667,109) (2010.75,105) (2010.833,102.7) (2010.917,101.9) (2011,99) (2011.083,101.6) (2011.167,115.3) (2011.25,101.6) (2011.333,110.1) (2011.417,108.5) (2011.5,101) (2011.583,78.3) (2011.667,110) (2011.75,106.4) (2011.833,106.3) (2011.917,100.2) (2012,99.3) (2012.083,99.9) (2012.167,110.3) (2012.25,99.8) (2012.333,96.1) (2012.417,108.5) (2012.5,103.8) (2012.583,78.8) (2012.667,102.9) (2012.75,107.6) (2012.833,101.9) (2012.917,91.5) (2013,96.3) (2013.083,95.7) (2013.167,103.9) (2013.25,103.4) (2013.333,96.2) (2013.417,105.5) (2013.5,105.2) (2013.583,73.4) (2013.667,103.3) (2013.75,109.3) (2013.833,99) (2013.917,94.6) (2014,96.8) (2014.083,97.1) (2014.167,104.9) (2014.25,102.9) (2014.333,92.4) (2014.417,104.8) (2014.5,103.3) (2014.583,71.5) (2014.667,107.2) (2014.75,107.7) (2014.833,95.5) (2014.917,98.4) (2015,94.6) (2015.083,96.1) (2015.167,108.4) (2015.25,102.4) (2015.333,91) (2015.417,111.8) (2015.5,101.1) (2015.583,76.1) (2015.667,109.1) (2015.75,107.7) (2015.833,101.8) (2015.917,99.9) (2016,95.1) (2016.083,99.6) (2016.167,108.3) (2016.25,103.3) (2016.333,98.6) (2016.417,110.3) (2016.5,95.8) (2016.583,79.7) (2016.667,107.9) (2016.75,103.4) (2016.833,104.7) (2016.917,99.7) (2017,98.9) (2017.083,97.1) (2017.167,114.5) (2017.25,98) (2017.333,102.7) (2017.417,111.4) (2017.5,99.5) (2017.583,81.4) (2017.667,108.2) (2017.75,113.2) (2017.833,111) (2017.917,99.5) (2018,101.8) (2018.083,98.6) (2018.167,112.9) (2018.25,103) (2018.333,98.7) (2018.417,112.8) (2018.5,106.6) (2018.583,82.6) (2018.667,104.7) (2018.75,116) (2018.833,109.6) (2018.917,97.6) (2019,103.8) (2019.083,102) (2019.167,111.6) (2019.25,107.2) (2019.333,105.2) (2019.417,106) (2019.5,109.8) (2019.583,78.8) (2019.667,109) (2019.75,116.5) (2019.833,104) (2019.917,97.8) (2020,101) (2020.083,100.1) (2020.167,91.8) (2020.25,66.7) (2020.333,73.7) (2020.417,98.2) (2020.5,97.4) (2020.583,71.7) (2020.667,104.7) (2020.75,106.7) (2020.833,101.6) (2020.917,96.6)};}
\end{axis}
\end{tikzpicture} 

### La tendance-cycle (2)

Pour l'analyse conjoncturelle, on étudie généralement des séries désaisonnalisées
$$
X_t - S_t =TC_t
+I_t
$$

. . .

\medskip

La présence de l'irrégulier peut rendre l'interprétation difficile, un lissage supplémentaire peut être utilisé :
$$
(X_t - S_t) - I_t =TC_t
$$

. . . 

Tendance-cycle publiée par peu d'instituts (ONS, Statistics Canada, ABS) mais volonté de faire des bonnes pratiques au niveau européen (Destatis).
Utile pour analyser le cycle des affaires.

. . . 

Critères importants de la tendance-cycle :

1. minimiser les révisions

2. minimiser le nombre de faux points de retournement

3. détecter correctement et \highlight{rapidement} les (bons) points de retournement



### Estimations de la TC et moyennes mobiles (1)


\bcattention Objectif différent de celui des méthodes d'analyse des cycles économiques

. . .

$TC_t$ généralement estimée sur une série \highlight{sans} saisonnalité

. . .

Méthode de décomposition X-13ARIMA une des plus utilisées : études de méthodes non-paramétriques pour estimer $TC_t$


. . .


\highlight{Moyennes mobiles} (ou \highlight{filtres linéaires}) omniprésents dans l'extraction de la tendance-cycle et la désaisonnalisation (e.g. : X-13ARIMA) :
$$
M_\theta(X_t)=\sum_{k=-p}^{+f}\theta_kX_{t+k}
$$

### Estimations de la TC et moyennes mobiles (1)


Appliquer $M_\theta$ sur $X_t=\e^{-i\omega t}$ va avoir deux effets : 
$$
M_{\theta}X_t = \sum_{k=-p}^{+f} \theta_k \e^{-i \omega (t+k)}
= \left(\sum_{k=-p}^{+f} \theta_k \e^{-i \omega k}\right)\cdot X_t = G_\theta(\omega)\e^{-i\Phi_\theta(\omega)} X_t
$$


::: {.incremental}

1. Multiplier le niveau par $G_{\theta}\left(\omega\right)$ (*gain*)

2. Créer un *déphasage* $\Phi_\theta(\omega)/\omega$ : affecte détection des points de retournement

:::




\begin{figure}[!ht]
\pgfplotsset{width=\textwidth,height=4cm,every axis legend/.append style={font=\footnotesize,
  at={(0.5,-0.1)},
  anchor=north}
    }
\begin{tikzpicture}
\begin{axis}[
xtick={0,3.14159,...,15.70795},
xticklabels={0,$\pi$,$2\pi$,$3\pi$,$4\pi$,$5\pi$}
]
\addplot[domain=0:5*pi,smooth]    plot (\x,{sin(\x * (pi/2) r)});
\addplot[domain=0:5*pi,smooth, dashed]
  plot (\x,{1/2*sin(\x* pi/2 r )+1/2*sin((\x -1) * pi/2 r)});
\draw[<->](axis cs: 1.5,1)--(axis cs: 1.5,0.7071068)
  node[pos=0.5, right]{\scriptsize $G_{\theta_0}(\omega)$};
\only<2->{
\draw[<->] (axis cs: 3, -0.70710680-0.05)--(axis cs: 3.5,-0.7071068-0.05)
  node[pos=0.5, below right]{\scriptsize $\Phi_{\theta_0}(\omega)$};}
\end{axis}
\end{tikzpicture}
\end{figure}


### Estimations de la TC et moyennes mobiles (2)

\faArrowCircleRight{} Généralement, utilisation de filtres \highlight{symétriques} ($p=f$ et $\theta_{-i}=\theta_i$)

$$
M_\theta(X_t)=\sum_{k=-p}^{+p}\theta_kX_{t+k}, \quad\text{avec }\theta_{-i}=\theta_i
$$

. . .


\faArrowCircleRight{} Pour l'estimation en \highlightbf{temps réel}, utilisation de filtres \highlight{asymétriques} ($f<p$) $\implies$ révision et détection avec retard des points de retournement (\highlight{déphasage})

$$
\text{ex : }M_\theta(X_t)=\sum_{k=-p}^{0}\theta_kX_{t+k}
$$

. . .

Solution classique : prolonger la série par prévision et utiliser filtre symétrique
\faArrowCircleRight{} revient à utiliser des filtres asymétriques optimisés avec certains critères   
\faArrowCircleRight{} sous-optimal pour séries très variables

### Illustration avec climats des affaires dans les matériels de transport

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/tc_finale.pdf")
```
\footnotesize 
https://www.insee.fr/fr/statistiques/6522175


### Évaluer la qualité des estimations avec prév. implicites

Fonction `rjd3filters::implicit_forecast`

$$
\forall q, \underbrace{\sum_{i=-h}^0 v_iy_i + \sum_{i=1}^h v_iy_i*}_{\text{lissage par }v\text{ de la série prolongée}}
=\underbrace{\sum_{i=-h}^0 w_i^qy_i + \sum_{i=1}^h w_i^qy_i*}_{\text{lissage par }w^q\text{ de la série prolongée}}\text{ avec }\forall i > q,w_i^q=0
$$
Ce qui est équivalent à :
$$
\forall q, \quad \sum_{i=1}^h (v_i- w_i^q) y_i^*
=\sum_{i=-h}^0 (w_i^q-v_i)y_i.
$$
Matriciellement :

\begin{equation}
\resizebox{\textwidth}{!}{$
\begin{pmatrix}
  v_1 & v_2 & \cdots & v_h \\
  v_1 - w_1^1 & v_2 & \cdots & v_h \\
  \vdots & \vdots & \cdots & \vdots \\
   v_1 - w_1^{h-1} & v_2-w_2^{h-1} & \cdots & v_h
\end{pmatrix}
\begin{pmatrix}y_1^* \\ \vdots \\ y_h^*\end{pmatrix}=
\begin{pmatrix}
  w_{-h}^0 - v_{-h} & w_{-(h-1)}^0 - v_{-(h-1)} & \cdots & w_{0}^0 - v_{0} \\
  w_{-h}^1 - v_{-h} & w_{-(h-1)}^1 - v_{-(h-1)} & \cdots & w_{0}^1 - v_{0} \\
  \vdots & \vdots & \cdots & \vdots \\
  w_{-h}^{h-1} - v_{-h} & w_{-(h-1)}^{h-1} - v_{-(h-1)} & \cdots & w_{0}^{h-1} - v_{0}
\end{pmatrix}
\begin{pmatrix}y_{-h} \\ \vdots \\ y_0\end{pmatrix}.$}
\end{equation}



### Objectifs

Objectifs de cette étude :

-  Étudier et comparer des approches récentes pour l'extraction de la tendance-cycle en temps réel : Régression polynomiale locale (Proietti et Luati 2008) ; RKHS (Dagum et Bianconcini 2016) ; Optimisation sous contrainte d’une somme pondérée de critères (Grun-Rehomme *et ali* 2018, Wildi et McElroy, 2019)

- On se concentre uniquement sur les moyennes mobiles asymétriques et pas sur l'estimation finale

. . .

- Montrer qu'il est possible d'établir une théorie générale englobant toutes ces méthodes et expliquer les liens entre les méthodes.

- Permet d'avoir une revue de la littérature de l'existant.

. . .

- Présenter le package \faIcon{r-project} `rjd3filters` https://github.com/rjdemetra/rjd3filters


# Méthodes étudiées

## Filtre symétrique

### Moyenne mobile symétrique d'Henderson

::::{.columns}
:::{.column width=55%}

\footnotesize
```{r h13, out.height="0.4\\paperheight", fig.align="center"}
library(rjd3filters)
f <- lp_filter(6, kernel = "Henderson")
plot_coef(f, q = 6, legend = FALSE,
          main="Henderson 13 termes")
```
:::
:::{.column width=45%}

MM Henderson (utilisé dans X-13ARIMA) largement répandue pour estimer $TC_t$

\medskip

MM Henderson préserve les tendances polynomiales de degré 3 et minimise le critère de "lissage" ($\sum(\nabla^3\theta_i)^2$)

\medskip

Sur séries mensuelles : MM de 13 termes généralement

:::
::::

## Polynômes Locaux

### Polynômes Locaux : `rjd3filters::lp_filter()`

Hypothèse : $y_t=\mu_t+\varepsilon_t$ avec $\varepsilon_t\overset{i.i.d}{\sim}\mathcal N(0,\sigma^2)$

$\mu_t$ localement approchée par un polynôme de degré $d$:
$$
\forall j\in\left\llbracket -h,h\right\rrbracket : y_{t+j}=m_{t+j}+\varepsilon_{t+j},\quad m_{t+j}=\sum_{i=0}^{d}\beta_{i}j^{i}
$$

. . .

Estimation en utilisant les WLS avec *noyaux*: $\hat{\beta}=(X'KX)^{1}X'Ky$ et
$$
\hat{m}_{t}=\hat\beta_0=w'y=\sum_{j=-h}^{h}w_{j}y_{t-j}
\text{ \faArrowCircleRight{} équivalent à une moyenne mobile symétrique}
$$
\faArrowCircleRight{} Filtre de Henderson avec $d=3$ et noyau spécifique.

### Filtres asymétriques : `rjd3filters::lp_filter()`

1. Même méthode mais moins de données (DAF) $\iff$ minimiser les révisions sous mêmes contraintes polynomiales

\faArrowCircleRight{} **sans biais** mais **beaucoup de variance**

\faArrowCircleRight{} utilisé dans STL



\pause

2. Minimisation des révisions sous contraintes polynomiales :

    1. *Linear-Constant* (LC): $y_t$ linéaire and $v$ reproduit les constantes (\highlight{Musgrave})

    2. *Quadratic-Linear* (QL): $y_t$ quadratique et $v$ reproduit droites

    3. *Cubic-Quadratic* (CQ): $y_t$ cubique et $v$ reproduit tendances quadratiques

    \faArrowCircleRight{} Filtres asymétriques $v$ dépendent de "IC-Ratio"

. . .

\bcsmbh modèles simples facilement interprétables

\bcsmmh Déphasage non contrôlé \faArrowCircleRight{} méthode étendue dans `rjd3filters::lp_filter()`

. . .

\faDesktop{} Visualisation https://aqlt.shinyapps.io/FiltersProperties/

### Coefficients

```{r out.height="90%", echo=FALSE}
knitr::include_graphics("img/coefs_lp.pdf")
```

### Illustration (1)

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/lp_es.pdf")
```

### Illustration (2)

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/lp_if.pdf")
```

## Filtres et Reproducing Kernel Hilbert Space (RKHS)

### Filtres RKHS : `rjd3filters::rkhs_filter()`

- Utilisation de la théorie des RKHS pour approcher le filtre d'Henderson

- Avec $K_p$ une **fonction de noyau** définie sur $[-1,1]$, le filtre symétrique :
$$
\forall j\in\left\llbracket -h,h\right\rrbracket: w_{j}=\frac{K_p(j/b)}{\sum_{i=-h}^{^h}K_p(i/b)}
$$

\onslide<3->{\faArrowCircleRight{} avec $b=h+1$ et $K_p$ spécifique on retrouve le filtre d'Henderson}

\pause


- Pour les filtres asymétriques :
$$
\forall j\in\left\llbracket -h,q\right\rrbracket: w_{a,j}=\frac{K_p(j/b)}{\sum_{i=-h}^{^q}K_p(i/b)}
$$

\pause\pause\faArrowCircleRight{} $b$ choisit par optimisation, e.g. minimisant les révisions ($b_{q,\Gamma}$), les révisions liées à la fonction de gain ($b_{q,G}$) et celles liées au déphasage ($b_{q,\varphi}$)

### Filtres asymétriques

::::{.columns}
:::{.column width=65%}

\bcsmmh Plusieurs extremum

\footnotesize
```{r rkhstimeliness, out.height="0.4\\paperheight", fig.align="center"}
library(rjd3filters)
fun <- rkhs_optimization_fun(horizon = 6,
            leads = 5, degree = 3,
            asymmetricCriterion = "Timeliness")
plot(fun, 5.6, 12, xlab = "b",
     ylab = "Timeliness", main = "6X5 filter")
rkhs_optimal_bw()
```
:::
:::{.column width=30%}

\bigskip

\bcsmbh Méthode généralisable à des filtres avec fréquences irrégulières

:::
::::

### Coefficients

```{r out.height="90%", echo=FALSE}
knitr::include_graphics("img/coefs_rkhs.pdf")
```

### Illustration (1)

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/rkhs.pdf")
```


## Minimisation sous contrainte : FST et ATS

### Approche FST : `rjd3filters::fst_filter()`

Minimisation sous contrainte d'une somme pondérée de 3 critères :

$$
\begin{cases}
\underset{\theta}{\min} & J(\theta)=
\alpha F_g(\theta)+\beta S_g(\theta)+\gamma T_g(\theta)\\
s.c. & C\theta=a
\end{cases}
$$
$F_g$ fidélité (*fidelity*, réduction de variance $\sum_{k=-p}^{+f} \theta_k^2$), $S_g$ lissage  (*smoothness*, critère d'Henderson $\sum_{j}(\nabla^{3}\theta_{j})^{2}$), $T_g$ temporalité (*timeliness*, déphasage $\int_{0}^{2\pi/12}\rho_{\theta}(\omega)\sin(\varphi_{\theta}(\omega))^{2}\ud\omega$)

. . .

::: {.summary data-latex=""}
- \bcsmbh Solution unique
  
- \bcsmmh Poids non normalisés \bcsmbh

- Filtres asymétriques indépendants des données et du filtre symétrique

:::


### Approche ATS `rjd3filters::dfa_filter()` {.allowframebreaks}

Décomposition de l'EQM :
\begin{align*}
&\E{(y_{t}-\hat{y}_{t})^{2}}=\frac{1}{2\pi}\int_{-\pi}^{\pi}\left|\Gamma_s(\omega)-{\Gamma_\theta}(\omega)\right|^{2}h(\omega)\ud\omega \nonumber
\\&\quad=\frac{1}{2\pi}\times2\times\int_{0}^{\pi}\left|\Gamma_s(\omega)-{\Gamma_\theta}(\omega)\right|^{2}h(\omega)\ud\omega
\end{align*}
et
\begin{align*}
&\left|\Gamma_s(\omega)-\Gamma_\theta(\omega)\right|^{2}=\rho_s(\omega)^{2}+\rho_\theta(\omega)^{2} + \\
&\qquad \phantom{=}2\rho_s(\lambda)\rho_\theta(\lambda)\left(1-\cos(\varphi_s(\omega)-\varphi_\theta(\omega)\right) \\
 &\qquad =\left(\rho_s(\omega)-\rho_\theta(\omega)\right)^{2}+\\
&\qquad \phantom{=}4\rho_s(\lambda)\rho_\theta(\lambda)\sin^{2}\left(\frac{\varphi_s(\omega)-\varphi_\theta(\omega)}{2}\right)
\end{align*}

Ce qui conduit à 
\begin{align*}
A_w&= 2\int_0^{\omega_1}\left(\rho_s(\omega)-\rho_\theta(\omega)\right)^{2}h(\omega)\ud\omega\\
T_w&= 8\int_0^{\omega_1}\rho_s(\lambda)\rho_\theta(\lambda)\sin^{2}\left(\frac{\varphi_\theta(\omega)}{2}\right)h(\omega)\ud\omega\\
S_w&= 2\int_{\omega_1}^\pi\left(\rho_s(\omega)^{2}-\rho_\theta(\omega)\right)^{2}h(\omega)\ud\omega\\
R_w&= 8\int_{\omega_1}^\pi\rho_s(\lambda)\rho_\theta(\lambda)\sin^{2}\left(\frac{\varphi_\theta(\omega)}{2}\right)h(\omega)\ud\omega\\
\end{align*}

Minimisation d'une somme pondérée de 3 critères :
$$
\mathcal{M}(\vartheta_{1},\vartheta_{2})=\vartheta_{1}T_w(\theta)+\vartheta_{2}S_w(\theta)+(1-\vartheta_{1}-\vartheta_{2})A_w(\theta)
$$
$\implies$ minimisation sous contraintes linéaires avec $h(\omega)=1$


::: {.summary data-latex=""}
- \bcsmbh Poids ont un sens
  
- \bcsmmh Résidus pas toujours négligeables
  
- \bcsmmh Pas unicité de la solution
:::


### Difficulté du choix des poids

Comment choisir les poids dans FST et AST (DFA) ? 


::: {.incremental}

- Minimiser que la *timeliness* ? introduit trop de variance

- Minimiser les révisions ? on néglige le déphasage

- Faire quadrillage du plan et une analyse empirique du déphasage ? 
C'est ce qui est fait avec FST en prenant les poids qui minimisent le déphasage sur les séries simulées (avec différents niveaux de variabilité).
Toujours du filtre préservant les polynômes de degré 2 avec $\alpha$=0,00 (fidelity), $\beta$=0,05 (smoothness) et $\gamma$=0,95 (timeliness).
:::


### Illustration FST

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/fst.pdf")
```


# Extensions

## Choix de la fenêtre

### Combien de termes utiliser les MM asymétriques ?  {.allowframebreaks}

Actuellement on utilise toujours autant de points dans le passé (6) que la MM symétriques pour les estimations intermédiaires : hypothèse raisonnable ? Faudrait-il utiliser plus ou moins de points dans le passé ?

Critères classiques : validation croisée, CP-Mallow, AIC, Rice-T :

$$
CV(\hat\mu)=\frac{1}{n-2h}\sum_{t=h+1}^{n-h}\frac{(y_t-\hat \mu_t)^2}{(1-w_0)^2}
$$
$$
CP(\hat\mu)=\frac{1}{\sigma^2}\sum_{t=h+1}^{n-h}(y_t-\hat \mu_t)^2 - (n-2h)(1-2w_0)
$$
Mais en général leur minimisation ne donne pas de bon résultats (critères peu discriminants)

Pistes à explorer :

1. Méthodes plus complexes de sélection de la fenêtre (e.g. Fan et Gijbels 1992)

2. Méthode des plus proches voisins : utiliser toujours le même nombre de points (e.g. toujours 13 points)

## Paramétrisation locale des méthodes polynomiales


### Estimation de la pente {.allowframebreaks}

Régression non paramétrique : $y_i=\mu(x_i)+\varepsilon_i$ avec $\varepsilon_i$ un terme d'erreur.

Avec Taylor, pour tout point $x_0$, si $\mu$ est différentiable $d$ fois, alors :
$$
\forall x \::\:\mu(x) = \mu(x_0) + \mu'(x_0)(x-x_0)+\dots +
\frac{\mu^{(d)}(x_0)}{d!}(x-a)^d+R_d(x),
$$


Régression polynomiale

Hypothèse : $y_t=\mu_t+\varepsilon_t$ avec $\varepsilon_t\overset{i.i.d}{\sim}\mathcal N(0,\sigma^2)$

$\mu_t$ localement approchée par un polynôme de degré $d$:
$$
\forall j\in\left\llbracket -h,h\right\rrbracket : y_{t+j}=\sum_{i=0}^{d}\beta_{i}j^{i}+\varepsilon_{t+j}
$$

Estimation en utilisant les WLS avec *noyaux* : $\hat{\beta}=(X'KX)^{1}X'Ky$ et
$$
\hat{m}_{t}=\hat\beta_0=e_1'\hat{\beta} =w'y=\sum_{j=-h}^{h}w_{j}y_{t-j}\text{ avec }
e_1=\begin{pmatrix}1\\ 0\\\vdots\\0\end{pmatrix}
$$
Et de la même façon :
$$
\begin{cases}
\hat\beta_1 = \widehat{\mu'(t)}= e_2'\hat{\beta}\qquad(\ne \widehat{\mu(t)}') \\
\hat\beta_2 = \widehat{\mu''(t)}= e_3'\hat{\beta}
\end{cases}
$$

Dans la méthode LC, en fin de période on suppose :
$$
y_t=\beta_0+\beta_1t+\varepsilon_t\text{ avec }\varepsilon_t\sim\mathcal N (0,\sigma^2)
$$
Filtres asymétriques dépendent du ratio $|\beta_1/\sigma|$ qui est toujours supposé constant : peu de sens au niveau global, notamment dans les périodes de points de retournement ($\beta_1\simeq 0$)


```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/local_ic_tp.pdf")
```



Idée : paramétrisation locale
$$
\begin{cases}
\hat\sigma^2=\frac{1}{n-2h}\sum_{t=h+1}^{n-h}\frac{(y_t-\hat \mu_t)^2}{1-2w_0^2+\sum w_i^2}\\
\beta_1\text{ et }\beta_2 \text{ estimés par MM (DAF par simplification)}
\end{cases}
$$

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/mm_penteconcavite.pdf")
```

Rmq: il y a (encore) de fortes révisions entre la première et deuxième estimation, on pourrait utiliser méthode QL pour avoir les estimateurs de la pente

Spoil : marche plutôt bien

### Illustration (1)

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/lp_local_es.pdf")
```

### Illustration (2)

```{r , echo=FALSE, out.width="100%"}
knitr::include_graphics("img/ex/lp_local_if.pdf")
```


# Comparaison des méthodes

## Méthodologie
### Méthodologie

Comparaison des différentes méthodes sur séries simulées (avec 3 niveaux de variabilité) et séries réelles :

1. Estimation de la tendance-cycle à chaque date en utilisant les différentes méthodes et un filtre symétrique de 13 termes

. . .

2. À chaque date, estimation des points de retournement :

    - redressements : $y_{t-3}\geq y_{t-2}\geq y_{t-1}<y_t\leq y_{t+1}$

    - ralentissements : $y_{t-3}\leq y_{t-2}\leq y_{t-1}>y_t\geq y_{t+1}$

Déphasage = temps nécessaire pour détecter le bon point de retournement \highlight{sans révision} ($\ne$ des papiers classiques)

. . .


3. Calcul des révisions avec deux critères :

$$
\mathbb E\left[
\left|\frac{
y_{t|t+q} - y_{t|last}
}{
y_{t|last}
}\right|
\right]\quad
\text{ et }
\quad
\mathbb E\left[
\left|\frac{
y_{t|t+q} - y_{t|t+q+1}
}{
y_{t|t+q+1}
}\right|
\right]
$$

### Séries simulées {.allowframebreaks}

De façon similaire à Darne et Dagum (2009), on simule $y_t= C_t+ T_t + I_t$ entre janvier 1960 et décembre 2020 :

- $C_t = \rho [\cos (2 \pi t / \lambda) +\sin (2 \pi t / \lambda)]$, $\lambda=72$ (cycles de 6 ans, 19 points de retournement détectables) 

- $T_t = T_{t-1} + \nu_t$ avec $\nu_t \sim \mathcal{N}(0, \sigma_\nu^2)$, $\sigma_\nu=0,08$

- $I_t = e_t$ avec $e_t \sim \mathcal{N}(0, \sigma_e^2)$

Niveau de variabilité :

- variabilité faible (rapport signal/bruit fort) : $\sigma_e^2=0,2$ et $\rho = 3,0,\, 3,5$ ou $4,0$ (0,9 $\geq$ I-C ratio $\geq$ 0,7)

- variabilité moyenne (rapport signal/bruit moyen) : $\sigma_e^2=0,3$ et $\rho = 1,5,\, 2,0$ ou $3,0$ (2,3 $\geq$ I-C ratio $\geq$ 1,4)

- variabilité forte (rapport signal/bruit élevé) : $\sigma_e^2=0,4$ et $\rho = 0,5,\, 0,7$ ou $1,0$ (8,9 $\geq$ I-C ratio $\geq$ 5,2)


```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("img/simul_data.pdf")
```

## Application
### Résultats sur séries simulées

Voir <https://aqlt.github.io/DT-est-tr-tc/sec-comparison.html#comparaison>

### Résultats sur des séries réelles

Voir <https://aqlt.github.io/DT-est-tr-tc/sec-comparison.html#s%C3%A9rie-r%C3%A9elle>


### Nouvelle Bibliographique

Estela Bee Dagum & Silvia Bianconcini (June 2023): Monitoring the direction of the short-term trend of economic indicators

- étudient le filtre cascade avec une approximation via les RKHS en utilisant noyau triangulaire (coefficients non retrouvé avec `rjd3filters`)

- proposent deux tests statistiques pour comparer les méthodes en termes de révisions et de point de retournement

- Comparent les méthodes en étudiant deux séries de la FRED

# Conclusion

## Conclusion

### Conclusion

- Dans la construction des filtres asymétriques:

1. on peut se restreindre à ceux qui conservent les polynômes de degré au plus 1 (et exclure les filtres QL, CQ et DAF)

\bigskip

. . .


2. on peut utiliser le filtre LC pour les estimations proches de l'estimation finale



\bigskip

. . .

- Dans certains cas des méthodes alternatives à la prévision ARIMA peuvent être utilisées \faIcon{arrow-circle-right} `rjd3filters` peut aider à comparer les résultats (`rjd3filters::x11()` pour les intégrer dans X-11)


### What next\bcquestion

- Etudes sur d'autres méthodes comme Vasyechko et Grun-Rehomme (2014) ou Feng et Schäfer (2021) ou l'extension des méthodes polynomiales avec $T_g$

\bigskip

. . .



- Impact des points atypiques ? quid des méthodes robustes ?


### `rjd3filters`

Permet de générer toutes les moyennes mobiles de X-11 (y compris asymétriques) et de les combiner pour en étudier les propriétés.

Permet de refaire toutes les étapes de X-11 (y compris correction des points atypiques), voir : <https://github.com/rjdemetra/rjd3filters/blob/develop/vignettes/X11.Rmd>



### ex `rjd3filters` : filtres X-11

```{r, out.width="100%"}
knitr::include_graphics("img/gain_lp.pdf")
```

### ex `rjd3filters` : filtres X-11

```{r, out.width="100%"}
knitr::include_graphics("img/gain_autres.pdf")
```

# Et maintenant ?

### Suite de l'étude actuelle

Document de travail en cours de finalisation

Soumission au JOS autour de la paramétrisation locale

Objectif d'une soumission d'un article "informatique" au Journal of Statistical Software

. . .

Reste une autre étude. Projet de recherche :

> Le second objectif de ce projet sera d’étudier l’impact de points atypiques sur les différentes méthodes d’extraction de cycle et sur la détection des points de retournement.

> Cet objectif d’étude d’impact des points atypiques amènera à également s’intéresser à l’utilisation de méthodes robustes pour l’estimation de la tendance-cycle, par exemple par l’utilisation de médianes mobiles (Tukey, 1971), mais aussi dans les autres étapes de la désaisonnalisation (pré-ajustement, estimation de la composante saisonnière, etc.).


### Merci pour votre attention {.noframenumbering}

